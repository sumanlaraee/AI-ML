{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumanlaraee/AI-ML/blob/main/peft_bnb_whisper_large_v2_training_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cefac89"
      },
      "source": [
        "# Finetuning Whisper-large-V2 on Colab using PEFT-Lora + BNB INT8 training"
      ],
      "id": "5cefac89"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "090fa3ed"
      },
      "source": [
        "In this Colab, we present a step-by-step guide on how to fine-tune Whisper for any multilingual ASR dataset using Hugging Face ðŸ¤— Transformers and ðŸ¤— PEFT. Using ðŸ¤— PEFT and `bitsandbytes`, you can train the `whisper-large-v2` seamlessly on a colab with T4 GPU (16 GB VRAM). In this notebook, with most parts from [fine_tune_whisper.ipynb](https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/fine_tune_whisper.ipynb#scrollTo=BRdrdFIeU78w) is adapted to train using PEFT LoRA+BNB INT8.\n",
        "\n",
        "For more details on model, datasets and metrics, refer blog [Fine-Tune Whisper For Multilingual ASR with ðŸ¤— Transformers](https://huggingface.co/blog/fine-tune-whisper)\n",
        "\n"
      ],
      "id": "090fa3ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "625e47a0"
      },
      "source": [
        "## Inital Setup"
      ],
      "id": "625e47a0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_Ivl7qlX0dz",
        "outputId": "c1496e79-5ead-4a06-a191-8ed7cf748d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-7l10z04u\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-7l10z04u\n",
            "  Resolved https://github.com/huggingface/transformers to commit 5275ef6f3d4a1a78a25e958496cde48fd0257dc2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (2025.1.31)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.12.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.20.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.11)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets>=2.6.1          #required\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install librosa\n",
        "!pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "!pip install gradio\n",
        "!pip install -q bitsandbytes datasets accelerate loralib\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git@main"
      ],
      "id": "r_Ivl7qlX0dz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a528c1a"
      },
      "source": [
        "Linking the notebook to the Hub is straightforward - it simply requires entering your Hub authentication token when prompted. Find your Hub authentication token [here](https://huggingface.co/settings/tokens):"
      ],
      "id": "8a528c1a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1da5fff"
      },
      "outputs": [],
      "source": [
        "# Select CUDA device index       #required\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "model_name_or_path = \"openai/whisper-large-v2\"\n",
        "language = \"pashto\"\n",
        "language_abbr = \"mr\"\n",
        "task = \"transcribe\"\n",
        "dataset_name = \"mozilla-foundation/common_voice_11_0\""
      ],
      "id": "e1da5fff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "805b1c56"
      },
      "source": [
        "## Load Dataset"
      ],
      "id": "805b1c56"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d_oKEy1swuGy"
      },
      "id": "d_oKEy1swuGy"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch             #required\n",
        "import torchaudio\n",
        "import json\n",
        "from datasets import Dataset, DatasetDict, Audio\n",
        "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor, TrainingArguments, Trainer\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "# Set model details\n",
        "model_name_or_path = \"openai/whisper-large-v2\"\n",
        "language = \"pashto\"\n",
        "task = \"transcribe\"\n",
        "\n",
        "# Load processor components\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name_or_path)\n",
        "tokenizer = WhisperTokenizer.from_pretrained(model_name_or_path, language=language, task=task)\n",
        "processor = WhisperProcessor.from_pretrained(model_name_or_path, language=language, task=task)\n",
        "\n",
        "# Define paths\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/audios\"\n",
        "PROCESSED_DIR = \"/content/processed_audio\"\n",
        "TRANSCRIPT_PATH = \"/content/sentences.json\"\n",
        "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
        "\n",
        "# Convert `.mpeg` and `.wav` files to 16kHz `.wav`\n",
        "def preprocess_audio():\n",
        "    for file in os.listdir(AUDIO_DIR):\n",
        "        if file.endswith((\".mpeg\", \".wav\")):\n",
        "            input_path = os.path.join(AUDIO_DIR, file)\n",
        "            output_path = os.path.join(PROCESSED_DIR, file.rsplit(\".\", 1)[0] + \".wav\")\n",
        "            waveform, sample_rate = torchaudio.load(input_path)\n",
        "            if sample_rate != 16000:\n",
        "                transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "                waveform = transform(waveform)\n",
        "            torchaudio.save(output_path, waveform, 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
        "preprocess_audio()\n",
        "\n",
        "# Load transcriptions\n",
        "with open(TRANSCRIPT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "sentences = data[2][\"data\"]\n",
        "\n",
        "# Match audio files with transcriptions\n",
        "dataset_dict = {\"audio\": [], \"text\": []}\n",
        "for entry in sentences:\n",
        "    for file in os.listdir(PROCESSED_DIR):\n",
        "        if entry[\"sentence_id\"] in file:\n",
        "            dataset_dict[\"audio\"].append(os.path.join(PROCESSED_DIR, file))\n",
        "            dataset_dict[\"text\"].append(entry[\"sentence\"])\n",
        "            break\n",
        "\n",
        "# Convert dictionary to Hugging Face Dataset\n",
        "dataset = Dataset.from_dict(dataset_dict).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "dataset = DatasetDict({\"train\": split_dataset[\"train\"], \"validation\": split_dataset[\"test\"]})\n",
        "\n",
        "# Function to process dataset\n",
        "# Function to process dataset (Fixed)\n",
        "import numpy as np\n",
        "\n",
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # Extract features\n",
        "    input_features = feature_extractor(\n",
        "        audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]\n",
        "    ).input_features[0]\n",
        "\n",
        "    # âœ… Ensure fixed length of 3000\n",
        "    expected_seq_length = 3000\n",
        "    current_length = input_features.shape[-1]\n",
        "\n",
        "    if current_length > expected_seq_length:\n",
        "        input_features = input_features[..., :expected_seq_length]  # Truncate\n",
        "    elif current_length < expected_seq_length:\n",
        "        pad_width = expected_seq_length - current_length\n",
        "        input_features = np.pad(\n",
        "            input_features, ((0, 0), (0, pad_width)), mode=\"constant\", constant_values=0\n",
        "        )  # Pad with zeros\n",
        "\n",
        "    batch[\"input_features\"] = input_features\n",
        "    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n",
        "\n",
        "    return batch\n",
        "\n",
        "\n",
        "\n",
        "# Apply to dataset\n",
        "dataset = dataset.map(prepare_dataset, remove_columns=[\"audio\", \"text\"])\n",
        "\n",
        "# âœ… Modified Data Collator to Fix Padding Issues\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # Extract input features\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features if \"input_features\" in feature]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # Extract labels and pad them\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features if \"labels\" in feature]\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # Ensure labels are properly masked\n",
        "        labels = labels_batch[\"input_ids\"]\n",
        "        labels[labels_batch.attention_mask == 0] = -100  # Ignore padding tokens in loss calculation\n",
        "\n",
        "        # Handle potential mismatches in dimensions\n",
        "        max_length = labels.shape[1]\n",
        "        batch_size = labels.shape[0]\n",
        "\n",
        "        if batch[\"input_features\"].shape[1] != max_length:\n",
        "            batch[\"input_features\"] = torch.nn.functional.pad(\n",
        "                batch[\"input_features\"], (0, max_length - batch[\"input_features\"].shape[1])\n",
        "            )\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch\n",
        "\n",
        "# Use the fixed data collator\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "f68e5493af214b17b9b01d1b06fc5fe0",
            "491d79aa01974b0c8c2599c890273bd2",
            "6206a73278c94df8bd5d7f452e750f40",
            "6c96f07acad6467190418299035d7585",
            "0d287568ec094469a205f8b55861f305",
            "2c80bc112bf94fd295b9bb882f8d1153",
            "89057775e565427eaf1f51efc007e12c",
            "213d94f50c71450880493f10b5952ea4",
            "53d7badf3c2943e59e6cf63ae9647694",
            "61943162f4884a1389f4b9eb2f396068",
            "f585f4a8fa014ef0b5d02729f717a437",
            "4fa50f4a86f14c849cd923c8c33e2267",
            "fc540c2c0199450c8c00b2b7856b1534",
            "75f99040bb1c4c5288db9731e9cc7bf0",
            "2a78ea286d2f4ae194f6f0a30fe63db2",
            "3f25843d23a84af997b1f483114a3619",
            "ecb7d63c08244466bda5261ceda28dee",
            "323f8a6e414a443697d1b5e5d0117ed7",
            "8a848ce217df44d2a12670a1acf8d467",
            "adfbb1df1f494452a37b203a9b4bff51",
            "ed8e5a36edc941a295f62cceb34af6cb",
            "3015e8838b0b4a198ccd38436e56d375"
          ]
        },
        "id": "2oKSClz-wuzC",
        "outputId": "c72b8d5b-ae01-434f-a235-8389d2a4bd63"
      },
      "id": "2oKSClz-wuzC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f68e5493af214b17b9b01d1b06fc5fe0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fa50f4a86f14c849cd923c8c33e2267"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b22b4011-f31f-4b57-b684-c52332f92890"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"wer\")"
      ],
      "id": "b22b4011-f31f-4b57-b684-c52332f92890"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f32cab6-31f0-4cb9-af4c-40ba0f5fc508"
      },
      "source": [
        "We then simply have to define a function that takes our model\n",
        "predictions and returns the WER metric. This function, called\n",
        "`compute_metrics`, first replaces `-100` with the `pad_token_id`\n",
        "in the `label_ids` (undoing the step we applied in the\n",
        "data collator to ignore padded tokens correctly in the loss).\n",
        "It then decodes the predicted and label ids to strings. Finally,\n",
        "it computes the WER between the predictions and reference labels:"
      ],
      "id": "4f32cab6-31f0-4cb9-af4c-40ba0f5fc508"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23959a70-22d0-4ffe-9fa1-72b61e75bb52"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}"
      ],
      "id": "23959a70-22d0-4ffe-9fa1-72b61e75bb52"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daf2a825-6d9f-4a23-b145-c37c0039075b"
      },
      "source": [
        "###Â Load a Pre-Trained Checkpoint"
      ],
      "id": "daf2a825-6d9f-4a23-b145-c37c0039075b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "437a97fa-4864-476b-8abc-f28b8166cfa5"
      },
      "source": [
        "Now let's load the pre-trained Whisper `small` checkpoint. Again, this\n",
        "is trivial through use of ðŸ¤— Transformers!"
      ],
      "id": "437a97fa-4864-476b-8abc-f28b8166cfa5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a10cc4b-07ec-4ebd-ac1d-7c601023594f"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperForConditionalGeneration    #required\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name_or_path)"
      ],
      "id": "5a10cc4b-07ec-4ebd-ac1d-7c601023594f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a15ead5f-2277-4a39-937b-585c2497b2df"
      },
      "source": [
        "Override generation arguments - no tokens are forced as decoder outputs (see [`forced_decoder_ids`](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.forced_decoder_ids)), no tokens are suppressed during generation (see [`suppress_tokens`](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.suppress_tokens)):"
      ],
      "id": "a15ead5f-2277-4a39-937b-585c2497b2df"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62038ba3-88ed-4fce-84db-338f50dcd04f"
      },
      "outputs": [],
      "source": [
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ],
      "id": "62038ba3-88ed-4fce-84db-338f50dcd04f"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade peft #required\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pCAjo_SldZy4",
        "outputId": "23d3630e-cabb-4a49-dfef-ae701830d2e8"
      },
      "id": "pCAjo_SldZy4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.1.dev0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.50.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.4.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = torch.compile(model)\n"
      ],
      "metadata": {
        "id": "ITsY9qKE7mBN"
      },
      "id": "ITsY9qKE7mBN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VWSxudXwdfAL"
      },
      "id": "VWSxudXwdfAL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR-_yaEOPsfQ"
      },
      "source": [
        "### Post-processing on the model\n",
        "\n",
        "Finally, we need to apply some post-processing on the 8-bit model to enable training, let's freeze all our layers, and cast the layer-norm in `float32` for stability. We also cast the output of the last layer in `float32` for the same reasons."
      ],
      "id": "bR-_yaEOPsfQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjl4j4RJPmPR"
      },
      "source": [
        "### Apply LoRA\n",
        "\n",
        "Here comes the magic with `peft`! Let's load a `PeftModel` and specify that we are going to use low-rank adapters (LoRA) using `get_peft_model` utility function from `peft`."
      ],
      "id": "Vjl4j4RJPmPR"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSpeechSeq2Seq, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# Define quantization configuration\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,  # Use 4-bit quantization\n",
        "    bnb_4bit_compute_dtype=torch.float16,  # FP16 computation\n",
        "    bnb_4bit_use_double_quant=True,  # Additional memory optimization\n",
        "    llm_int8_enable_fp32_cpu_offload=True  # Offload FP32 layers to CPU\n",
        ")\n",
        "\n",
        "# Load model with quantization\n",
        "model_name = \"openai/whisper-large-v2\"\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quantization_config,  # Apply quantization\n",
        "    device_map=\"auto\"  # Auto-assign model to available GPUs\n",
        ")\n"
      ],
      "metadata": {
        "id": "vomXlLAu0-F1"
      },
      "id": "vomXlLAu0-F1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1bmHGVbj1_6G"
      },
      "id": "1bmHGVbj1_6G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3906d436"
      },
      "source": [
        "We are ONLY using **1%** of the total trainable parameters, thereby performing **Parameter-Efficient Fine-Tuning**"
      ],
      "id": "3906d436"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2178dea4-80ca-47b6-b6ea-ba1915c90c06"
      },
      "source": [
        "### Define the Training Configuration"
      ],
      "id": "2178dea4-80ca-47b6-b6ea-ba1915c90c06"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c21af1e9-0188-4134-ac82-defc7bdcc436"
      },
      "source": [
        "In the final step, we define all the parameters related to training. For more detail on the training arguments, refer to the Seq2SeqTrainingArguments [docs](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments)."
      ],
      "id": "c21af1e9-0188-4134-ac82-defc7bdcc436"
    },
    {
      "cell_type": "code",
      "source": [
        "model.gradient_checkpointing_enable()\n"
      ],
      "metadata": {
        "id": "FCB_f2i_zxa6"
      },
      "id": "FCB_f2i_zxa6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "1Y5aAEJPz0Li"
      },
      "id": "1Y5aAEJPz0Li",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperForConditionalGeneration\n",
        "\n",
        "# Load the Whisper model\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name_or_path)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./whisper-checkpoints\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    logging_steps=100,\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=500,\n",
        "    save_total_limit=2,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=8,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",  # âœ… Disables wandb properly\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRJ2NwPx4LWf",
        "outputId": "be1b96bc-5053-4b62-9280-9571d7721b9a"
      },
      "id": "MRJ2NwPx4LWf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3a944d8-3112-4552-82a0-be25988b3857"
      },
      "source": [
        "**Few Important Notes:**\n",
        "1. `remove_unused_columns=False` and `label_names=[\"labels\"]` are required as the PeftModel's forward doesn't have the signature of the base model's forward.\n",
        "\n",
        "2. INT8 training required autocasting. `predict_with_generate` can't be passed to Trainer because it internally calls transformer's `generate` without autocasting leading to errors.\n",
        "\n",
        "3. Because of point 2, `compute_metrics` shouldn't be passed to `Seq2SeqTrainer` as seen below. (commented out)"
      ],
      "id": "b3a944d8-3112-4552-82a0-be25988b3857"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oVipviRpEY-x"
      },
      "id": "oVipviRpEY-x"
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Fix Trainer to use correct model inputs\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    tokenizer=processor.feature_extractor,  # âœ… Use feature extractor, not tokenizer\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Run training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "krVgsoRPEbOc",
        "outputId": "b0e87355-fa20-4b70-8668-945c853f3700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "id": "krVgsoRPEbOc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-a24e835be875>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 6.12 MiB is free. Process 710807 has 14.73 GiB memory in use. Of the allocated memory 14.15 GiB is allocated by PyTorch, and 483.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a24e835be875>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# âœ… Fix Trainer to use correct model inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m trainer = Trainer(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quantization_method\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mQuantizationMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBITS_AND_BYTES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         ):\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;31m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m         \u001b[0;31m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tie_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3258\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m                 )\n\u001b[0;32m-> 3260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 6.12 MiB is free. Process 710807 has 14.73 GiB memory in use. Of the allocated memory 14.15 GiB is allocated by PyTorch, and 483.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "dd863f41e0484e999b8548ee7af8e058",
            "ed659b121be3438fa5ff7847725a4e52"
          ]
        },
        "id": "0576aa2a",
        "outputId": "af58b2eb-80f4-430c-9968-d169ed03c75a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading the following files to smangrul/openai-whisper-large-v2-LORA-colab: adapter_model.bin,adapter_config.json\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd863f41e0484e999b8548ee7af8e058",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed659b121be3438fa5ff7847725a4e52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.bin:   0%|          | 0.00/63.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "smangrul/openai-whisper-large-v2-LORA-colab\n"
          ]
        }
      ],
      "source": [
        "model_name_or_path = \"openai/whisper-large-v2\"\n",
        "peft_model_id = \"smangrul/\" + f\"{model_name_or_path}-{model.peft_config.peft_type}-colab\".replace(\"/\", \"-\")\n",
        "model.push_to_hub(peft_model_id)\n",
        "print(peft_model_id)"
      ],
      "id": "0576aa2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlyyOGnPgi_I"
      },
      "source": [
        "# Evaluation and Inference"
      ],
      "id": "SlyyOGnPgi_I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "36e70a8474654c07b6160c81bb8f71ac",
            "c302ca92974f4b9298d3a6fc66578e60"
          ]
        },
        "id": "273a996c",
        "outputId": "a51fc133-a2c7-4d38-eeca-92bbc9a0a71e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36e70a8474654c07b6160c81bb8f71ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (â€¦)/adapter_config.json:   0%|          | 0.00/358 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/config.json\n",
            "Model config WhisperConfig {\n",
            "  \"_name_or_path\": \"openai/whisper-large-v2\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"WhisperForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"begin_suppress_tokens\": [\n",
            "    220,\n",
            "    50257\n",
            "  ],\n",
            "  \"bos_token_id\": 50257,\n",
            "  \"d_model\": 1280,\n",
            "  \"decoder_attention_heads\": 20,\n",
            "  \"decoder_ffn_dim\": 5120,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 32,\n",
            "  \"decoder_start_token_id\": 50258,\n",
            "  \"dropout\": 0.0,\n",
            "  \"encoder_attention_heads\": 20,\n",
            "  \"encoder_ffn_dim\": 5120,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 32,\n",
            "  \"eos_token_id\": 50257,\n",
            "  \"forced_decoder_ids\": [\n",
            "    [\n",
            "      1,\n",
            "      50259\n",
            "    ],\n",
            "    [\n",
            "      2,\n",
            "      50359\n",
            "    ],\n",
            "    [\n",
            "      3,\n",
            "      50363\n",
            "    ]\n",
            "  ],\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"max_length\": 448,\n",
            "  \"max_source_positions\": 1500,\n",
            "  \"max_target_positions\": 448,\n",
            "  \"model_type\": \"whisper\",\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_mel_bins\": 80,\n",
            "  \"pad_token_id\": 50257,\n",
            "  \"scale_embedding\": false,\n",
            "  \"suppress_tokens\": [\n",
            "    1,\n",
            "    2,\n",
            "    7,\n",
            "    8,\n",
            "    9,\n",
            "    10,\n",
            "    14,\n",
            "    25,\n",
            "    26,\n",
            "    27,\n",
            "    28,\n",
            "    29,\n",
            "    31,\n",
            "    58,\n",
            "    59,\n",
            "    60,\n",
            "    61,\n",
            "    62,\n",
            "    63,\n",
            "    90,\n",
            "    91,\n",
            "    92,\n",
            "    93,\n",
            "    359,\n",
            "    503,\n",
            "    522,\n",
            "    542,\n",
            "    873,\n",
            "    893,\n",
            "    902,\n",
            "    918,\n",
            "    922,\n",
            "    931,\n",
            "    1350,\n",
            "    1853,\n",
            "    1982,\n",
            "    2460,\n",
            "    2627,\n",
            "    3246,\n",
            "    3253,\n",
            "    3268,\n",
            "    3536,\n",
            "    3846,\n",
            "    3961,\n",
            "    4183,\n",
            "    4667,\n",
            "    6585,\n",
            "    6647,\n",
            "    7273,\n",
            "    9061,\n",
            "    9383,\n",
            "    10428,\n",
            "    10929,\n",
            "    11938,\n",
            "    12033,\n",
            "    12331,\n",
            "    12562,\n",
            "    13793,\n",
            "    14157,\n",
            "    14635,\n",
            "    15265,\n",
            "    15618,\n",
            "    16553,\n",
            "    16604,\n",
            "    18362,\n",
            "    18956,\n",
            "    20075,\n",
            "    21675,\n",
            "    22520,\n",
            "    26130,\n",
            "    26161,\n",
            "    26435,\n",
            "    28279,\n",
            "    29464,\n",
            "    31650,\n",
            "    32302,\n",
            "    32470,\n",
            "    36865,\n",
            "    42863,\n",
            "    47425,\n",
            "    49870,\n",
            "    50254,\n",
            "    50258,\n",
            "    50360,\n",
            "    50361,\n",
            "    50362\n",
            "  ],\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.27.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51865\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/pytorch_model.bin\n",
            "Instantiating WhisperForConditionalGeneration model under default dtype torch.float16.\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"begin_suppress_tokens\": [\n",
            "    220,\n",
            "    50257\n",
            "  ],\n",
            "  \"bos_token_id\": 50257,\n",
            "  \"decoder_start_token_id\": 50258,\n",
            "  \"eos_token_id\": 50257,\n",
            "  \"forced_decoder_ids\": [\n",
            "    [\n",
            "      1,\n",
            "      50259\n",
            "    ],\n",
            "    [\n",
            "      2,\n",
            "      50359\n",
            "    ],\n",
            "    [\n",
            "      3,\n",
            "      50363\n",
            "    ]\n",
            "  ],\n",
            "  \"max_length\": 448,\n",
            "  \"pad_token_id\": 50257,\n",
            "  \"suppress_tokens\": [\n",
            "    1,\n",
            "    2,\n",
            "    7,\n",
            "    8,\n",
            "    9,\n",
            "    10,\n",
            "    14,\n",
            "    25,\n",
            "    26,\n",
            "    27,\n",
            "    28,\n",
            "    29,\n",
            "    31,\n",
            "    58,\n",
            "    59,\n",
            "    60,\n",
            "    61,\n",
            "    62,\n",
            "    63,\n",
            "    90,\n",
            "    91,\n",
            "    92,\n",
            "    93,\n",
            "    359,\n",
            "    503,\n",
            "    522,\n",
            "    542,\n",
            "    873,\n",
            "    893,\n",
            "    902,\n",
            "    918,\n",
            "    922,\n",
            "    931,\n",
            "    1350,\n",
            "    1853,\n",
            "    1982,\n",
            "    2460,\n",
            "    2627,\n",
            "    3246,\n",
            "    3253,\n",
            "    3268,\n",
            "    3536,\n",
            "    3846,\n",
            "    3961,\n",
            "    4183,\n",
            "    4667,\n",
            "    6585,\n",
            "    6647,\n",
            "    7273,\n",
            "    9061,\n",
            "    9383,\n",
            "    10428,\n",
            "    10929,\n",
            "    11938,\n",
            "    12033,\n",
            "    12331,\n",
            "    12562,\n",
            "    13793,\n",
            "    14157,\n",
            "    14635,\n",
            "    15265,\n",
            "    15618,\n",
            "    16553,\n",
            "    16604,\n",
            "    18362,\n",
            "    18956,\n",
            "    20075,\n",
            "    21675,\n",
            "    22520,\n",
            "    26130,\n",
            "    26161,\n",
            "    26435,\n",
            "    28279,\n",
            "    29464,\n",
            "    31650,\n",
            "    32302,\n",
            "    32470,\n",
            "    36865,\n",
            "    42863,\n",
            "    47425,\n",
            "    49870,\n",
            "    50254,\n",
            "    50258,\n",
            "    50360,\n",
            "    50361,\n",
            "    50362\n",
            "  ],\n",
            "  \"transformers_version\": \"4.27.0.dev0\"\n",
            "}\n",
            "\n",
            "Detected 8-bit loading: activating 8-bit loading for this model\n",
            "All model checkpoint weights were used when initializing WhisperForConditionalGeneration.\n",
            "\n",
            "All the weights of WhisperForConditionalGeneration were initialized from the model checkpoint at openai/whisper-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use WhisperForConditionalGeneration for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"begin_suppress_tokens\": [\n",
            "    220,\n",
            "    50257\n",
            "  ],\n",
            "  \"bos_token_id\": 50257,\n",
            "  \"decoder_start_token_id\": 50258,\n",
            "  \"eos_token_id\": 50257,\n",
            "  \"forced_decoder_ids\": [\n",
            "    [\n",
            "      1,\n",
            "      null\n",
            "    ],\n",
            "    [\n",
            "      2,\n",
            "      50359\n",
            "    ]\n",
            "  ],\n",
            "  \"is_multilingual\": true,\n",
            "  \"lang_to_id\": {\n",
            "    \"<|af|>\": 50327,\n",
            "    \"<|am|>\": 50334,\n",
            "    \"<|ar|>\": 50272,\n",
            "    \"<|as|>\": 50350,\n",
            "    \"<|az|>\": 50304,\n",
            "    \"<|ba|>\": 50355,\n",
            "    \"<|be|>\": 50330,\n",
            "    \"<|bg|>\": 50292,\n",
            "    \"<|bn|>\": 50302,\n",
            "    \"<|bo|>\": 50347,\n",
            "    \"<|br|>\": 50309,\n",
            "    \"<|bs|>\": 50315,\n",
            "    \"<|ca|>\": 50270,\n",
            "    \"<|cs|>\": 50283,\n",
            "    \"<|cy|>\": 50297,\n",
            "    \"<|da|>\": 50285,\n",
            "    \"<|de|>\": 50261,\n",
            "    \"<|el|>\": 50281,\n",
            "    \"<|en|>\": 50259,\n",
            "    \"<|es|>\": 50262,\n",
            "    \"<|et|>\": 50307,\n",
            "    \"<|eu|>\": 50310,\n",
            "    \"<|fa|>\": 50300,\n",
            "    \"<|fi|>\": 50277,\n",
            "    \"<|fo|>\": 50338,\n",
            "    \"<|fr|>\": 50265,\n",
            "    \"<|gl|>\": 50319,\n",
            "    \"<|gu|>\": 50333,\n",
            "    \"<|haw|>\": 50352,\n",
            "    \"<|ha|>\": 50354,\n",
            "    \"<|he|>\": 50279,\n",
            "    \"<|hi|>\": 50276,\n",
            "    \"<|hr|>\": 50291,\n",
            "    \"<|ht|>\": 50339,\n",
            "    \"<|hu|>\": 50286,\n",
            "    \"<|hy|>\": 50312,\n",
            "    \"<|id|>\": 50275,\n",
            "    \"<|is|>\": 50311,\n",
            "    \"<|it|>\": 50274,\n",
            "    \"<|ja|>\": 50266,\n",
            "    \"<|jw|>\": 50356,\n",
            "    \"<|ka|>\": 50329,\n",
            "    \"<|kk|>\": 50316,\n",
            "    \"<|km|>\": 50323,\n",
            "    \"<|kn|>\": 50306,\n",
            "    \"<|ko|>\": 50264,\n",
            "    \"<|la|>\": 50294,\n",
            "    \"<|lb|>\": 50345,\n",
            "    \"<|ln|>\": 50353,\n",
            "    \"<|lo|>\": 50336,\n",
            "    \"<|lt|>\": 50293,\n",
            "    \"<|lv|>\": 50301,\n",
            "    \"<|mg|>\": 50349,\n",
            "    \"<|mi|>\": 50295,\n",
            "    \"<|mk|>\": 50308,\n",
            "    \"<|ml|>\": 50296,\n",
            "    \"<|mn|>\": 50314,\n",
            "    \"<|mr|>\": 50320,\n",
            "    \"<|ms|>\": 50282,\n",
            "    \"<|mt|>\": 50343,\n",
            "    \"<|my|>\": 50346,\n",
            "    \"<|ne|>\": 50313,\n",
            "    \"<|nl|>\": 50271,\n",
            "    \"<|nn|>\": 50342,\n",
            "    \"<|no|>\": 50288,\n",
            "    \"<|oc|>\": 50328,\n",
            "    \"<|pa|>\": 50321,\n",
            "    \"<|pl|>\": 50269,\n",
            "    \"<|ps|>\": 50340,\n",
            "    \"<|pt|>\": 50267,\n",
            "    \"<|ro|>\": 50284,\n",
            "    \"<|ru|>\": 50263,\n",
            "    \"<|sa|>\": 50344,\n",
            "    \"<|sd|>\": 50332,\n",
            "    \"<|si|>\": 50322,\n",
            "    \"<|sk|>\": 50298,\n",
            "    \"<|sl|>\": 50305,\n",
            "    \"<|sn|>\": 50324,\n",
            "    \"<|so|>\": 50326,\n",
            "    \"<|sq|>\": 50317,\n",
            "    \"<|sr|>\": 50303,\n",
            "    \"<|su|>\": 50357,\n",
            "    \"<|sv|>\": 50273,\n",
            "    \"<|sw|>\": 50318,\n",
            "    \"<|ta|>\": 50287,\n",
            "    \"<|te|>\": 50299,\n",
            "    \"<|tg|>\": 50331,\n",
            "    \"<|th|>\": 50289,\n",
            "    \"<|tk|>\": 50341,\n",
            "    \"<|tl|>\": 50348,\n",
            "    \"<|tr|>\": 50268,\n",
            "    \"<|tt|>\": 50351,\n",
            "    \"<|uk|>\": 50280,\n",
            "    \"<|ur|>\": 50290,\n",
            "    \"<|uz|>\": 50337,\n",
            "    \"<|vi|>\": 50278,\n",
            "    \"<|yi|>\": 50335,\n",
            "    \"<|yo|>\": 50325,\n",
            "    \"<|zh|>\": 50260\n",
            "  },\n",
            "  \"max_initial_timestamp_index\": 1,\n",
            "  \"max_length\": 448,\n",
            "  \"no_timestamps_token_id\": 50363,\n",
            "  \"pad_token_id\": 50256,\n",
            "  \"return_timestamps\": false,\n",
            "  \"suppress_tokens\": [\n",
            "    1,\n",
            "    2,\n",
            "    7,\n",
            "    8,\n",
            "    9,\n",
            "    10,\n",
            "    14,\n",
            "    25,\n",
            "    26,\n",
            "    27,\n",
            "    28,\n",
            "    29,\n",
            "    31,\n",
            "    58,\n",
            "    59,\n",
            "    60,\n",
            "    61,\n",
            "    62,\n",
            "    63,\n",
            "    90,\n",
            "    91,\n",
            "    92,\n",
            "    93,\n",
            "    359,\n",
            "    503,\n",
            "    522,\n",
            "    542,\n",
            "    873,\n",
            "    893,\n",
            "    902,\n",
            "    918,\n",
            "    922,\n",
            "    931,\n",
            "    1350,\n",
            "    1853,\n",
            "    1982,\n",
            "    2460,\n",
            "    2627,\n",
            "    3246,\n",
            "    3253,\n",
            "    3268,\n",
            "    3536,\n",
            "    3846,\n",
            "    3961,\n",
            "    4183,\n",
            "    4667,\n",
            "    6585,\n",
            "    6647,\n",
            "    7273,\n",
            "    9061,\n",
            "    9383,\n",
            "    10428,\n",
            "    10929,\n",
            "    11938,\n",
            "    12033,\n",
            "    12331,\n",
            "    12562,\n",
            "    13793,\n",
            "    14157,\n",
            "    14635,\n",
            "    15265,\n",
            "    15618,\n",
            "    16553,\n",
            "    16604,\n",
            "    18362,\n",
            "    18956,\n",
            "    20075,\n",
            "    21675,\n",
            "    22520,\n",
            "    26130,\n",
            "    26161,\n",
            "    26435,\n",
            "    28279,\n",
            "    29464,\n",
            "    31650,\n",
            "    32302,\n",
            "    32470,\n",
            "    36865,\n",
            "    42863,\n",
            "    47425,\n",
            "    49870,\n",
            "    50254,\n",
            "    50258,\n",
            "    50360,\n",
            "    50361,\n",
            "    50362\n",
            "  ],\n",
            "  \"task_to_id\": {\n",
            "    \"transcribe\": 50359,\n",
            "    \"translate\": 50358\n",
            "  },\n",
            "  \"transformers_version\": \"4.27.0.dev0\"\n",
            "}\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c302ca92974f4b9298d3a6fc66578e60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (â€¦)\"adapter_model.bin\";:   0%|          | 0.00/63.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import WhisperForConditionalGeneration, Seq2SeqTrainer\n",
        "\n",
        "peft_model_id = \"smangrul/openai-whisper-large-v2-LORA-colab\"\n",
        "peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\n",
        "    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)"
      ],
      "id": "273a996c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "401ceaa6",
        "outputId": "394409fa-b3ad-4444-bab0-3b1334aa9ac2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 227/227 [1:48:29<00:00, 28.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wer=36.74811424150603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "eval_dataloader = DataLoader(common_voice[\"test\"], batch_size=8, collate_fn=data_collator)\n",
        "\n",
        "model.eval()\n",
        "for step, batch in enumerate(tqdm(eval_dataloader)):\n",
        "    with torch.cuda.amp.autocast():\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = (\n",
        "                model.generate(\n",
        "                    input_features=batch[\"input_features\"].to(\"cuda\"),\n",
        "                    decoder_input_ids=batch[\"labels\"][:, :4].to(\"cuda\"),\n",
        "                    max_new_tokens=255,\n",
        "                )\n",
        "                .cpu()\n",
        "                .numpy()\n",
        "            )\n",
        "            labels = batch[\"labels\"].cpu().numpy()\n",
        "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "            metric.add_batch(\n",
        "                predictions=decoded_preds,\n",
        "                references=decoded_labels,\n",
        "            )\n",
        "    del generated_tokens, labels, batch\n",
        "    gc.collect()\n",
        "wer = 100 * metric.compute()\n",
        "print(f\"{wer=}\")"
      ],
      "id": "401ceaa6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZN4pTangw98"
      },
      "source": [
        "## Using AutomaticSpeechRecognitionPipeline"
      ],
      "id": "8ZN4pTangw98"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpDx1AOCgwuk"
      },
      "source": [
        "**Few important notes:**\n",
        "1. `pipe()` should be in the autocast context manager `with torch.cuda.amp.autocast():`\n",
        "2. `forced_decoder_ids` specifying the `language` being transcribed should be provided in `generate_kwargs` dict.\n",
        "3. You will get warning along the below lines which is **safe to ignore**.\n",
        "```\n",
        "The model 'PeftModel' is not supported for . Supported models are ['SpeechEncoderDecoderModel', 'Speech2TextForConditionalGeneration', 'SpeechT5ForSpeechToText', 'WhisperForConditionalGeneration', 'Data2VecAudioForCTC', 'HubertForCTC', 'MCTCTForCTC', 'SEWForCTC', 'SEWDForCTC', 'UniSpeechForCTC', 'UniSpeechSatForCTC', 'Wav2Vec2ForCTC', 'Wav2Vec2ConformerForCTC', 'WavLMForCTC'].\n",
        "\n",
        "```"
      ],
      "id": "hpDx1AOCgwuk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fa2b62a3",
        "outputId": "aeed0bfa-d9e7-4a4c-9e25-52225a074ec0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/config.json\n",
            "Model config WhisperConfig {\n",
            "  \"_name_or_path\": \"openai/whisper-large-v2\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"WhisperForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"begin_suppress_tokens\": [\n",
            "    220,\n",
            "    50257\n",
            "  ],\n",
            "  \"bos_token_id\": 50257,\n",
            "  \"d_model\": 1280,\n",
            "  \"decoder_attention_heads\": 20,\n",
            "  \"decoder_ffn_dim\": 5120,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 32,\n",
            "  \"decoder_start_token_id\": 50258,\n",
            "  \"dropout\": 0.0,\n",
            "  \"encoder_attention_heads\": 20,\n",
            "  \"encoder_ffn_dim\": 5120,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 32,\n",
            "  \"eos_token_id\": 50257,\n",
            "  \"forced_decoder_ids\": [\n",
            "    [\n",
            "      1,\n",
            "      50259\n",
            "    ],\n",
            "    [\n",
            "      2,\n",
            "      50359\n",
            "    ],\n",
            "    [\n",
            "      3,\n",
            "      50363\n",
            "    ]\n",
            "  ],\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"max_length\": 448,\n",
            "  \"max_source_positions\": 1500,\n",
            "  \"max_target_positions\": 448,\n",
            "  \"model_type\": \"whisper\",\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_mel_bins\": 80,\n",
            "  \"pad_token_id\": 50257,\n",
            "  \"scale_embedding\": false,\n",
            "  \"suppress_tokens\": [\n",
            "    1,\n",
            "    2,\n",
            "    7,\n",
            "    8,\n",
            "    9,\n",
            "    10,\n",
            "    14,\n",
            "    25,\n",
            "    26,\n",
            "    27,\n",
            "    28,\n",
            "    29,\n",
            "    31,\n",
            "    58,\n",
            "    59,\n",
            "    60,\n",
            "    61,\n",
            "    62,\n",
            "    63,\n",
            "    90,\n",
            "    91,\n",
            "    92,\n",
            "    93,\n",
            "    359,\n",
            "    503,\n",
            "    522,\n",
            "    542,\n",
            "    873,\n",
            "    893,\n",
            "    902,\n",
            "    918,\n",
            "    922,\n",
            "    931,\n",
            "    1350,\n",
            "    1853,\n",
            "    1982,\n",
            "    2460,\n",
            "    2627,\n",
            "    3246,\n",
            "    3253,\n",
            "    3268,\n",
            "    3536,\n",
            "    3846,\n",
            "    3961,\n",
            "    4183,\n",
            "    4667,\n",
            "    6585,\n",
            "    6647,\n",
            "    7273,\n",
            "    9061,\n",
            "    9383,\n",
            "    10428,\n",
            "    10929,\n",
            "    11938,\n",
            "    12033,\n",
            "    12331,\n",
            "    12562,\n",
            "    13793,\n",
            "    14157,\n",
            "    14635,\n",
            "    15265,\n",
            "    15618,\n",
            "    16553,\n",
            "    16604,\n",
            "    18362,\n",
            "    18956,\n",
            "    20075,\n",
            "    21675,\n",
            "    22520,\n",
            "    26130,\n",
            "    26161,\n",
            "    26435,\n",
            "    28279,\n",
            "    29464,\n",
            "    31650,\n",
            "    32302,\n",
            "    32470,\n",
            "    36865,\n",
            "    42863,\n",
            "    47425,\n",
            "    49870,\n",
            "    50254,\n",
            "    50258,\n",
            "    50360,\n",
            "    50361,\n",
            "    50362\n",
            "  ],\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.27.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51865\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/pytorch_model.bin\n",
            "Instantiating WhisperForConditionalGeneration model under default dtype torch.float16.\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"begin_suppress_tokens\": [\n",
            "    220,\n",
            "    50257\n",
            "  ],\n",
            "  \"bos_token_id\": 50257,\n",
            "  \"decoder_start_token_id\": 50258,\n",
            "  \"eos_token_id\": 50257,\n",
            "  \"forced_decoder_ids\": [\n",
            "    [\n",
            "      1,\n",
            "      50259\n",
            "    ],\n",
            "    [\n",
            "      2,\n",
            "      50359\n",
            "    ],\n",
            "    [\n",
            "      3,\n",
            "      50363\n",
            "    ]\n",
            "  ],\n",
            "  \"max_length\": 448,\n",
            "  \"pad_token_id\": 50257,\n",
            "  \"suppress_tokens\": [\n",
            "    1,\n",
            "    2,\n",
            "    7,\n",
            "    8,\n",
            "    9,\n",
            "    10,\n",
            "    14,\n",
            "    25,\n",
            "    26,\n",
            "    27,\n",
            "    28,\n",
            "    29,\n",
            "    31,\n",
            "    58,\n",
            "    59,\n",
            "    60,\n",
            "    61,\n",
            "    62,\n",
            "    63,\n",
            "    90,\n",
            "    91,\n",
            "    92,\n",
            "    93,\n",
            "    359,\n",
            "    503,\n",
            "    522,\n",
            "    542,\n",
            "    873,\n",
            "    893,\n",
            "    902,\n",
            "    918,\n",
            "    922,\n",
            "    931,\n",
            "    1350,\n",
            "    1853,\n",
            "    1982,\n",
            "    2460,\n",
            "    2627,\n",
            "    3246,\n",
            "    3253,\n",
            "    3268,\n",
            "    3536,\n",
            "    3846,\n",
            "    3961,\n",
            "    4183,\n",
            "    4667,\n",
            "    6585,\n",
            "    6647,\n",
            "    7273,\n",
            "    9061,\n",
            "    9383,\n",
            "    10428,\n",
            "    10929,\n",
            "    11938,\n",
            "    12033,\n",
            "    12331,\n",
            "    12562,\n",
            "    13793,\n",
            "    14157,\n",
            "    14635,\n",
            "    15265,\n",
            "    15618,\n",
            "    16553,\n",
            "    16604,\n",
            "    18362,\n",
            "    18956,\n",
            "    20075,\n",
            "    21675,\n",
            "    22520,\n",
            "    26130,\n",
            "    26161,\n",
            "    26435,\n",
            "    28279,\n",
            "    29464,\n",
            "    31650,\n",
            "    32302,\n",
            "    32470,\n",
            "    36865,\n",
            "    42863,\n",
            "    47425,\n",
            "    49870,\n",
            "    50254,\n",
            "    50258,\n",
            "    50360,\n",
            "    50361,\n",
            "    50362\n",
            "  ],\n",
            "  \"transformers_version\": \"4.27.0.dev0\"\n",
            "}\n",
            "\n",
            "Detected 8-bit loading: activating 8-bit loading for this model\n",
            "All model checkpoint weights were used when initializing WhisperForConditionalGeneration.\n",
            "\n",
            "All the weights of WhisperForConditionalGeneration were initialized from the model checkpoint at openai/whisper-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use WhisperForConditionalGeneration for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"begin_suppress_tokens\": [\n",
            "    220,\n",
            "    50257\n",
            "  ],\n",
            "  \"bos_token_id\": 50257,\n",
            "  \"decoder_start_token_id\": 50258,\n",
            "  \"eos_token_id\": 50257,\n",
            "  \"forced_decoder_ids\": [\n",
            "    [\n",
            "      1,\n",
            "      null\n",
            "    ],\n",
            "    [\n",
            "      2,\n",
            "      50359\n",
            "    ]\n",
            "  ],\n",
            "  \"is_multilingual\": true,\n",
            "  \"lang_to_id\": {\n",
            "    \"<|af|>\": 50327,\n",
            "    \"<|am|>\": 50334,\n",
            "    \"<|ar|>\": 50272,\n",
            "    \"<|as|>\": 50350,\n",
            "    \"<|az|>\": 50304,\n",
            "    \"<|ba|>\": 50355,\n",
            "    \"<|be|>\": 50330,\n",
            "    \"<|bg|>\": 50292,\n",
            "    \"<|bn|>\": 50302,\n",
            "    \"<|bo|>\": 50347,\n",
            "    \"<|br|>\": 50309,\n",
            "    \"<|bs|>\": 50315,\n",
            "    \"<|ca|>\": 50270,\n",
            "    \"<|cs|>\": 50283,\n",
            "    \"<|cy|>\": 50297,\n",
            "    \"<|da|>\": 50285,\n",
            "    \"<|de|>\": 50261,\n",
            "    \"<|el|>\": 50281,\n",
            "    \"<|en|>\": 50259,\n",
            "    \"<|es|>\": 50262,\n",
            "    \"<|et|>\": 50307,\n",
            "    \"<|eu|>\": 50310,\n",
            "    \"<|fa|>\": 50300,\n",
            "    \"<|fi|>\": 50277,\n",
            "    \"<|fo|>\": 50338,\n",
            "    \"<|fr|>\": 50265,\n",
            "    \"<|gl|>\": 50319,\n",
            "    \"<|gu|>\": 50333,\n",
            "    \"<|haw|>\": 50352,\n",
            "    \"<|ha|>\": 50354,\n",
            "    \"<|he|>\": 50279,\n",
            "    \"<|hi|>\": 50276,\n",
            "    \"<|hr|>\": 50291,\n",
            "    \"<|ht|>\": 50339,\n",
            "    \"<|hu|>\": 50286,\n",
            "    \"<|hy|>\": 50312,\n",
            "    \"<|id|>\": 50275,\n",
            "    \"<|is|>\": 50311,\n",
            "    \"<|it|>\": 50274,\n",
            "    \"<|ja|>\": 50266,\n",
            "    \"<|jw|>\": 50356,\n",
            "    \"<|ka|>\": 50329,\n",
            "    \"<|kk|>\": 50316,\n",
            "    \"<|km|>\": 50323,\n",
            "    \"<|kn|>\": 50306,\n",
            "    \"<|ko|>\": 50264,\n",
            "    \"<|la|>\": 50294,\n",
            "    \"<|lb|>\": 50345,\n",
            "    \"<|ln|>\": 50353,\n",
            "    \"<|lo|>\": 50336,\n",
            "    \"<|lt|>\": 50293,\n",
            "    \"<|lv|>\": 50301,\n",
            "    \"<|mg|>\": 50349,\n",
            "    \"<|mi|>\": 50295,\n",
            "    \"<|mk|>\": 50308,\n",
            "    \"<|ml|>\": 50296,\n",
            "    \"<|mn|>\": 50314,\n",
            "    \"<|mr|>\": 50320,\n",
            "    \"<|ms|>\": 50282,\n",
            "    \"<|mt|>\": 50343,\n",
            "    \"<|my|>\": 50346,\n",
            "    \"<|ne|>\": 50313,\n",
            "    \"<|nl|>\": 50271,\n",
            "    \"<|nn|>\": 50342,\n",
            "    \"<|no|>\": 50288,\n",
            "    \"<|oc|>\": 50328,\n",
            "    \"<|pa|>\": 50321,\n",
            "    \"<|pl|>\": 50269,\n",
            "    \"<|ps|>\": 50340,\n",
            "    \"<|pt|>\": 50267,\n",
            "    \"<|ro|>\": 50284,\n",
            "    \"<|ru|>\": 50263,\n",
            "    \"<|sa|>\": 50344,\n",
            "    \"<|sd|>\": 50332,\n",
            "    \"<|si|>\": 50322,\n",
            "    \"<|sk|>\": 50298,\n",
            "    \"<|sl|>\": 50305,\n",
            "    \"<|sn|>\": 50324,\n",
            "    \"<|so|>\": 50326,\n",
            "    \"<|sq|>\": 50317,\n",
            "    \"<|sr|>\": 50303,\n",
            "    \"<|su|>\": 50357,\n",
            "    \"<|sv|>\": 50273,\n",
            "    \"<|sw|>\": 50318,\n",
            "    \"<|ta|>\": 50287,\n",
            "    \"<|te|>\": 50299,\n",
            "    \"<|tg|>\": 50331,\n",
            "    \"<|th|>\": 50289,\n",
            "    \"<|tk|>\": 50341,\n",
            "    \"<|tl|>\": 50348,\n",
            "    \"<|tr|>\": 50268,\n",
            "    \"<|tt|>\": 50351,\n",
            "    \"<|uk|>\": 50280,\n",
            "    \"<|ur|>\": 50290,\n",
            "    \"<|uz|>\": 50337,\n",
            "    \"<|vi|>\": 50278,\n",
            "    \"<|yi|>\": 50335,\n",
            "    \"<|yo|>\": 50325,\n",
            "    \"<|zh|>\": 50260\n",
            "  },\n",
            "  \"max_initial_timestamp_index\": 1,\n",
            "  \"max_length\": 448,\n",
            "  \"no_timestamps_token_id\": 50363,\n",
            "  \"pad_token_id\": 50256,\n",
            "  \"return_timestamps\": false,\n",
            "  \"suppress_tokens\": [\n",
            "    1,\n",
            "    2,\n",
            "    7,\n",
            "    8,\n",
            "    9,\n",
            "    10,\n",
            "    14,\n",
            "    25,\n",
            "    26,\n",
            "    27,\n",
            "    28,\n",
            "    29,\n",
            "    31,\n",
            "    58,\n",
            "    59,\n",
            "    60,\n",
            "    61,\n",
            "    62,\n",
            "    63,\n",
            "    90,\n",
            "    91,\n",
            "    92,\n",
            "    93,\n",
            "    359,\n",
            "    503,\n",
            "    522,\n",
            "    542,\n",
            "    873,\n",
            "    893,\n",
            "    902,\n",
            "    918,\n",
            "    922,\n",
            "    931,\n",
            "    1350,\n",
            "    1853,\n",
            "    1982,\n",
            "    2460,\n",
            "    2627,\n",
            "    3246,\n",
            "    3253,\n",
            "    3268,\n",
            "    3536,\n",
            "    3846,\n",
            "    3961,\n",
            "    4183,\n",
            "    4667,\n",
            "    6585,\n",
            "    6647,\n",
            "    7273,\n",
            "    9061,\n",
            "    9383,\n",
            "    10428,\n",
            "    10929,\n",
            "    11938,\n",
            "    12033,\n",
            "    12331,\n",
            "    12562,\n",
            "    13793,\n",
            "    14157,\n",
            "    14635,\n",
            "    15265,\n",
            "    15618,\n",
            "    16553,\n",
            "    16604,\n",
            "    18362,\n",
            "    18956,\n",
            "    20075,\n",
            "    21675,\n",
            "    22520,\n",
            "    26130,\n",
            "    26161,\n",
            "    26435,\n",
            "    28279,\n",
            "    29464,\n",
            "    31650,\n",
            "    32302,\n",
            "    32470,\n",
            "    36865,\n",
            "    42863,\n",
            "    47425,\n",
            "    49870,\n",
            "    50254,\n",
            "    50258,\n",
            "    50360,\n",
            "    50361,\n",
            "    50362\n",
            "  ],\n",
            "  \"task_to_id\": {\n",
            "    \"transcribe\": 50359,\n",
            "    \"translate\": 50358\n",
            "  },\n",
            "  \"transformers_version\": \"4.27.0.dev0\"\n",
            "}\n",
            "\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/vocab.json\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/merges.txt\n",
            "loading file normalizer.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/normalizer.json\n",
            "loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/added_tokens.json\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/tokenizer_config.json\n",
            "Adding <|endoftext|> to the vocabulary\n",
            "Adding <|startoftranscript|> to the vocabulary\n",
            "Adding <|en|> to the vocabulary\n",
            "Adding <|zh|> to the vocabulary\n",
            "Adding <|de|> to the vocabulary\n",
            "Adding <|es|> to the vocabulary\n",
            "Adding <|ru|> to the vocabulary\n",
            "Adding <|ko|> to the vocabulary\n",
            "Adding <|fr|> to the vocabulary\n",
            "Adding <|ja|> to the vocabulary\n",
            "Adding <|pt|> to the vocabulary\n",
            "Adding <|tr|> to the vocabulary\n",
            "Adding <|pl|> to the vocabulary\n",
            "Adding <|ca|> to the vocabulary\n",
            "Adding <|nl|> to the vocabulary\n",
            "Adding <|ar|> to the vocabulary\n",
            "Adding <|sv|> to the vocabulary\n",
            "Adding <|it|> to the vocabulary\n",
            "Adding <|id|> to the vocabulary\n",
            "Adding <|hi|> to the vocabulary\n",
            "Adding <|fi|> to the vocabulary\n",
            "Adding <|vi|> to the vocabulary\n",
            "Adding <|he|> to the vocabulary\n",
            "Adding <|uk|> to the vocabulary\n",
            "Adding <|el|> to the vocabulary\n",
            "Adding <|ms|> to the vocabulary\n",
            "Adding <|cs|> to the vocabulary\n",
            "Adding <|ro|> to the vocabulary\n",
            "Adding <|da|> to the vocabulary\n",
            "Adding <|hu|> to the vocabulary\n",
            "Adding <|ta|> to the vocabulary\n",
            "Adding <|no|> to the vocabulary\n",
            "Adding <|th|> to the vocabulary\n",
            "Adding <|ur|> to the vocabulary\n",
            "Adding <|hr|> to the vocabulary\n",
            "Adding <|bg|> to the vocabulary\n",
            "Adding <|lt|> to the vocabulary\n",
            "Adding <|la|> to the vocabulary\n",
            "Adding <|mi|> to the vocabulary\n",
            "Adding <|ml|> to the vocabulary\n",
            "Adding <|cy|> to the vocabulary\n",
            "Adding <|sk|> to the vocabulary\n",
            "Adding <|te|> to the vocabulary\n",
            "Adding <|fa|> to the vocabulary\n",
            "Adding <|lv|> to the vocabulary\n",
            "Adding <|bn|> to the vocabulary\n",
            "Adding <|sr|> to the vocabulary\n",
            "Adding <|az|> to the vocabulary\n",
            "Adding <|sl|> to the vocabulary\n",
            "Adding <|kn|> to the vocabulary\n",
            "Adding <|et|> to the vocabulary\n",
            "Adding <|mk|> to the vocabulary\n",
            "Adding <|br|> to the vocabulary\n",
            "Adding <|eu|> to the vocabulary\n",
            "Adding <|is|> to the vocabulary\n",
            "Adding <|hy|> to the vocabulary\n",
            "Adding <|ne|> to the vocabulary\n",
            "Adding <|mn|> to the vocabulary\n",
            "Adding <|bs|> to the vocabulary\n",
            "Adding <|kk|> to the vocabulary\n",
            "Adding <|sq|> to the vocabulary\n",
            "Adding <|sw|> to the vocabulary\n",
            "Adding <|gl|> to the vocabulary\n",
            "Adding <|mr|> to the vocabulary\n",
            "Adding <|pa|> to the vocabulary\n",
            "Adding <|si|> to the vocabulary\n",
            "Adding <|km|> to the vocabulary\n",
            "Adding <|sn|> to the vocabulary\n",
            "Adding <|yo|> to the vocabulary\n",
            "Adding <|so|> to the vocabulary\n",
            "Adding <|af|> to the vocabulary\n",
            "Adding <|oc|> to the vocabulary\n",
            "Adding <|ka|> to the vocabulary\n",
            "Adding <|be|> to the vocabulary\n",
            "Adding <|tg|> to the vocabulary\n",
            "Adding <|sd|> to the vocabulary\n",
            "Adding <|gu|> to the vocabulary\n",
            "Adding <|am|> to the vocabulary\n",
            "Adding <|yi|> to the vocabulary\n",
            "Adding <|lo|> to the vocabulary\n",
            "Adding <|uz|> to the vocabulary\n",
            "Adding <|fo|> to the vocabulary\n",
            "Adding <|ht|> to the vocabulary\n",
            "Adding <|ps|> to the vocabulary\n",
            "Adding <|tk|> to the vocabulary\n",
            "Adding <|nn|> to the vocabulary\n",
            "Adding <|mt|> to the vocabulary\n",
            "Adding <|sa|> to the vocabulary\n",
            "Adding <|lb|> to the vocabulary\n",
            "Adding <|my|> to the vocabulary\n",
            "Adding <|bo|> to the vocabulary\n",
            "Adding <|tl|> to the vocabulary\n",
            "Adding <|mg|> to the vocabulary\n",
            "Adding <|as|> to the vocabulary\n",
            "Adding <|tt|> to the vocabulary\n",
            "Adding <|haw|> to the vocabulary\n",
            "Adding <|ln|> to the vocabulary\n",
            "Adding <|ha|> to the vocabulary\n",
            "Adding <|ba|> to the vocabulary\n",
            "Adding <|jw|> to the vocabulary\n",
            "Adding <|su|> to the vocabulary\n",
            "Adding <|translate|> to the vocabulary\n",
            "Adding <|transcribe|> to the vocabulary\n",
            "Adding <|startoflm|> to the vocabulary\n",
            "Adding <|startofprev|> to the vocabulary\n",
            "Adding <|nocaptions|> to the vocabulary\n",
            "Adding <|notimestamps|> to the vocabulary\n",
            "loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/preprocessor_config.json\n",
            "Feature extractor WhisperFeatureExtractor {\n",
            "  \"chunk_length\": 30,\n",
            "  \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
            "  \"feature_size\": 80,\n",
            "  \"hop_length\": 160,\n",
            "  \"n_fft\": 400,\n",
            "  \"n_samples\": 480000,\n",
            "  \"nb_max_frames\": 3000,\n",
            "  \"padding_side\": \"right\",\n",
            "  \"padding_value\": 0.0,\n",
            "  \"processor_class\": \"WhisperProcessor\",\n",
            "  \"return_attention_mask\": false,\n",
            "  \"sampling_rate\": 16000\n",
            "}\n",
            "\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/vocab.json\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/merges.txt\n",
            "loading file normalizer.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/normalizer.json\n",
            "loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/added_tokens.json\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--openai--whisper-large-v2/snapshots/bd0efe4d58db161e5ca3940e7c5940221e1b9646/tokenizer_config.json\n",
            "Adding <|endoftext|> to the vocabulary\n",
            "Adding <|startoftranscript|> to the vocabulary\n",
            "Adding <|en|> to the vocabulary\n",
            "Adding <|zh|> to the vocabulary\n",
            "Adding <|de|> to the vocabulary\n",
            "Adding <|es|> to the vocabulary\n",
            "Adding <|ru|> to the vocabulary\n",
            "Adding <|ko|> to the vocabulary\n",
            "Adding <|fr|> to the vocabulary\n",
            "Adding <|ja|> to the vocabulary\n",
            "Adding <|pt|> to the vocabulary\n",
            "Adding <|tr|> to the vocabulary\n",
            "Adding <|pl|> to the vocabulary\n",
            "Adding <|ca|> to the vocabulary\n",
            "Adding <|nl|> to the vocabulary\n",
            "Adding <|ar|> to the vocabulary\n",
            "Adding <|sv|> to the vocabulary\n",
            "Adding <|it|> to the vocabulary\n",
            "Adding <|id|> to the vocabulary\n",
            "Adding <|hi|> to the vocabulary\n",
            "Adding <|fi|> to the vocabulary\n",
            "Adding <|vi|> to the vocabulary\n",
            "Adding <|he|> to the vocabulary\n",
            "Adding <|uk|> to the vocabulary\n",
            "Adding <|el|> to the vocabulary\n",
            "Adding <|ms|> to the vocabulary\n",
            "Adding <|cs|> to the vocabulary\n",
            "Adding <|ro|> to the vocabulary\n",
            "Adding <|da|> to the vocabulary\n",
            "Adding <|hu|> to the vocabulary\n",
            "Adding <|ta|> to the vocabulary\n",
            "Adding <|no|> to the vocabulary\n",
            "Adding <|th|> to the vocabulary\n",
            "Adding <|ur|> to the vocabulary\n",
            "Adding <|hr|> to the vocabulary\n",
            "Adding <|bg|> to the vocabulary\n",
            "Adding <|lt|> to the vocabulary\n",
            "Adding <|la|> to the vocabulary\n",
            "Adding <|mi|> to the vocabulary\n",
            "Adding <|ml|> to the vocabulary\n",
            "Adding <|cy|> to the vocabulary\n",
            "Adding <|sk|> to the vocabulary\n",
            "Adding <|te|> to the vocabulary\n",
            "Adding <|fa|> to the vocabulary\n",
            "Adding <|lv|> to the vocabulary\n",
            "Adding <|bn|> to the vocabulary\n",
            "Adding <|sr|> to the vocabulary\n",
            "Adding <|az|> to the vocabulary\n",
            "Adding <|sl|> to the vocabulary\n",
            "Adding <|kn|> to the vocabulary\n",
            "Adding <|et|> to the vocabulary\n",
            "Adding <|mk|> to the vocabulary\n",
            "Adding <|br|> to the vocabulary\n",
            "Adding <|eu|> to the vocabulary\n",
            "Adding <|is|> to the vocabulary\n",
            "Adding <|hy|> to the vocabulary\n",
            "Adding <|ne|> to the vocabulary\n",
            "Adding <|mn|> to the vocabulary\n",
            "Adding <|bs|> to the vocabulary\n",
            "Adding <|kk|> to the vocabulary\n",
            "Adding <|sq|> to the vocabulary\n",
            "Adding <|sw|> to the vocabulary\n",
            "Adding <|gl|> to the vocabulary\n",
            "Adding <|mr|> to the vocabulary\n",
            "Adding <|pa|> to the vocabulary\n",
            "Adding <|si|> to the vocabulary\n",
            "Adding <|km|> to the vocabulary\n",
            "Adding <|sn|> to the vocabulary\n",
            "Adding <|yo|> to the vocabulary\n",
            "Adding <|so|> to the vocabulary\n",
            "Adding <|af|> to the vocabulary\n",
            "Adding <|oc|> to the vocabulary\n",
            "Adding <|ka|> to the vocabulary\n",
            "Adding <|be|> to the vocabulary\n",
            "Adding <|tg|> to the vocabulary\n",
            "Adding <|sd|> to the vocabulary\n",
            "Adding <|gu|> to the vocabulary\n",
            "Adding <|am|> to the vocabulary\n",
            "Adding <|yi|> to the vocabulary\n",
            "Adding <|lo|> to the vocabulary\n",
            "Adding <|uz|> to the vocabulary\n",
            "Adding <|fo|> to the vocabulary\n",
            "Adding <|ht|> to the vocabulary\n",
            "Adding <|ps|> to the vocabulary\n",
            "Adding <|tk|> to the vocabulary\n",
            "Adding <|nn|> to the vocabulary\n",
            "Adding <|mt|> to the vocabulary\n",
            "Adding <|sa|> to the vocabulary\n",
            "Adding <|lb|> to the vocabulary\n",
            "Adding <|my|> to the vocabulary\n",
            "Adding <|bo|> to the vocabulary\n",
            "Adding <|tl|> to the vocabulary\n",
            "Adding <|mg|> to the vocabulary\n",
            "Adding <|as|> to the vocabulary\n",
            "Adding <|tt|> to the vocabulary\n",
            "Adding <|haw|> to the vocabulary\n",
            "Adding <|ln|> to the vocabulary\n",
            "Adding <|ha|> to the vocabulary\n",
            "Adding <|ba|> to the vocabulary\n",
            "Adding <|jw|> to the vocabulary\n",
            "Adding <|su|> to the vocabulary\n",
            "Adding <|translate|> to the vocabulary\n",
            "Adding <|transcribe|> to the vocabulary\n",
            "Adding <|startoflm|> to the vocabulary\n",
            "Adding <|startofprev|> to the vocabulary\n",
            "Adding <|nocaptions|> to the vocabulary\n",
            "Adding <|notimestamps|> to the vocabulary\n",
            "The model 'PeftModel' is not supported for . Supported models are ['SpeechEncoderDecoderModel', 'Speech2TextForConditionalGeneration', 'SpeechT5ForSpeechToText', 'WhisperForConditionalGeneration', 'Data2VecAudioForCTC', 'HubertForCTC', 'MCTCTForCTC', 'SEWForCTC', 'SEWDForCTC', 'UniSpeechForCTC', 'UniSpeechSatForCTC', 'Wav2Vec2ForCTC', 'Wav2Vec2ConformerForCTC', 'WavLMForCTC'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ee6fef1c-b214-4067.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://ee6fef1c-b214-4067.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "from transformers import (\n",
        "    AutomaticSpeechRecognitionPipeline,\n",
        "    WhisperForConditionalGeneration,\n",
        "    WhisperTokenizer,\n",
        "    WhisperProcessor,\n",
        ")\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "\n",
        "peft_model_id = \"smangrul/openai-whisper-large-v2-LORA-colab\"\n",
        "language = \"Marathi\"\n",
        "task = \"transcribe\"\n",
        "peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\n",
        "    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "tokenizer = WhisperTokenizer.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
        "processor = WhisperProcessor.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
        "feature_extractor = processor.feature_extractor\n",
        "forced_decoder_ids = processor.get_decoder_prompt_ids(language=language, task=task)\n",
        "pipe = AutomaticSpeechRecognitionPipeline(model=model, tokenizer=tokenizer, feature_extractor=feature_extractor)\n",
        "\n",
        "\n",
        "def transcribe(audio):\n",
        "    with torch.cuda.amp.autocast():\n",
        "        text = pipe(audio, generate_kwargs={\"forced_decoder_ids\": forced_decoder_ids}, max_new_tokens=255)[\"text\"]\n",
        "    return text\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=transcribe,\n",
        "    inputs=gr.Audio(source=\"microphone\", type=\"filepath\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"PEFT LoRA + INT8 Whisper Large V2 Marathi\",\n",
        "    description=\"Realtime demo for Marathi speech recognition using `PEFT-LoRA+INT8` fine-tuned Whisper Large V2 model.\",\n",
        ")\n",
        "\n",
        "iface.launch(share=True)"
      ],
      "id": "fa2b62a3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XNn49f3BiLXa"
      },
      "outputs": [],
      "source": [],
      "id": "XNn49f3BiLXa"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f68e5493af214b17b9b01d1b06fc5fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_491d79aa01974b0c8c2599c890273bd2",
              "IPY_MODEL_6206a73278c94df8bd5d7f452e750f40",
              "IPY_MODEL_6c96f07acad6467190418299035d7585"
            ],
            "layout": "IPY_MODEL_0d287568ec094469a205f8b55861f305"
          }
        },
        "491d79aa01974b0c8c2599c890273bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c80bc112bf94fd295b9bb882f8d1153",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_89057775e565427eaf1f51efc007e12c",
            "value": "Map:â€‡100%"
          }
        },
        "6206a73278c94df8bd5d7f452e750f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_213d94f50c71450880493f10b5952ea4",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53d7badf3c2943e59e6cf63ae9647694",
            "value": 80
          }
        },
        "6c96f07acad6467190418299035d7585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61943162f4884a1389f4b9eb2f396068",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f585f4a8fa014ef0b5d02729f717a437",
            "value": "â€‡80/80â€‡[00:03&lt;00:00,â€‡36.70â€‡examples/s]"
          }
        },
        "0d287568ec094469a205f8b55861f305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c80bc112bf94fd295b9bb882f8d1153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89057775e565427eaf1f51efc007e12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "213d94f50c71450880493f10b5952ea4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53d7badf3c2943e59e6cf63ae9647694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61943162f4884a1389f4b9eb2f396068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f585f4a8fa014ef0b5d02729f717a437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fa50f4a86f14c849cd923c8c33e2267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc540c2c0199450c8c00b2b7856b1534",
              "IPY_MODEL_75f99040bb1c4c5288db9731e9cc7bf0",
              "IPY_MODEL_2a78ea286d2f4ae194f6f0a30fe63db2"
            ],
            "layout": "IPY_MODEL_3f25843d23a84af997b1f483114a3619"
          }
        },
        "fc540c2c0199450c8c00b2b7856b1534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecb7d63c08244466bda5261ceda28dee",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_323f8a6e414a443697d1b5e5d0117ed7",
            "value": "Map:â€‡100%"
          }
        },
        "75f99040bb1c4c5288db9731e9cc7bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a848ce217df44d2a12670a1acf8d467",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adfbb1df1f494452a37b203a9b4bff51",
            "value": 20
          }
        },
        "2a78ea286d2f4ae194f6f0a30fe63db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed8e5a36edc941a295f62cceb34af6cb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3015e8838b0b4a198ccd38436e56d375",
            "value": "â€‡20/20â€‡[00:00&lt;00:00,â€‡43.85â€‡examples/s]"
          }
        },
        "3f25843d23a84af997b1f483114a3619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecb7d63c08244466bda5261ceda28dee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "323f8a6e414a443697d1b5e5d0117ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a848ce217df44d2a12670a1acf8d467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adfbb1df1f494452a37b203a9b4bff51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed8e5a36edc941a295f62cceb34af6cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3015e8838b0b4a198ccd38436e56d375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}